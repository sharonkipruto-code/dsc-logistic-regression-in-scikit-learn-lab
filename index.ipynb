{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression in scikit-learn - Lab\n",
    "\n",
    "## Introduction \n",
    "\n",
    "In this lab, you are going to fit a logistic regression model to a dataset concerning heart disease. Whether or not a patient has heart disease is indicated in the column labeled `'target'`. 1 is for positive for heart disease while 0 indicates no heart disease.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this lab you will: \n",
    "\n",
    "- Fit a logistic regression model using scikit-learn \n",
    "\n",
    "\n",
    "## Let's get started!\n",
    "\n",
    "Run the following cells that import the necessary functions and import the dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary functions\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "df = pd.read_csv('heart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define appropriate `X` and `y` \n",
    "\n",
    "Recall the dataset contains information about whether or not a patient has heart disease and is indicated in the column labeled `'target'`. With that, define appropriate `X` (predictors) and `y` (target) in order to model whether or not a patient has heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into target and predictors\n",
    "y = df['target']\n",
    "X = df.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train- test split \n",
    "\n",
    "- Split the data into training and test sets \n",
    "- Assign 25% to the test set \n",
    "- Set the `random_state` to 0 \n",
    "\n",
    "N.B. To avoid possible data leakage, it is best to split the data first, and then normalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the data \n",
    "\n",
    "Normalize the data (`X`) prior to fitting the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481132</td>\n",
       "      <td>0.244292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.603053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.283105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.885496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.562500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.251142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.816794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  sex        cp  trestbps      chol  fbs  restecg   thalach  exang  \\\n",
       "0  0.708333  1.0  1.000000  0.481132  0.244292  1.0      0.0  0.603053    0.0   \n",
       "1  0.166667  1.0  0.666667  0.339623  0.283105  0.0      0.5  0.885496    0.0   \n",
       "2  0.250000  0.0  0.333333  0.339623  0.178082  0.0      0.0  0.770992    0.0   \n",
       "3  0.562500  1.0  0.333333  0.245283  0.251142  0.0      0.5  0.816794    0.0   \n",
       "4  0.583333  0.0  0.000000  0.245283  0.520548  0.0      0.5  0.702290    1.0   \n",
       "\n",
       "    oldpeak  slope   ca      thal  \n",
       "0  0.370968    0.0  0.0  0.333333  \n",
       "1  0.564516    0.0  0.0  0.666667  \n",
       "2  0.225806    1.0  0.0  0.666667  \n",
       "3  0.129032    1.0  0.0  0.666667  \n",
       "4  0.096774    1.0  0.0  0.666667  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "X = X.apply(lambda x : (x - x.min()) /(x.max() - x.min()), axis=0)\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a model\n",
    "\n",
    "- Instantiate `LogisticRegression`\n",
    "  - Make sure you don't include the intercept  \n",
    "  - set `C` to a very large number such as `1e12` \n",
    "  - Use the `'liblinear'` solver \n",
    "- Fit the model to the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1000000000000.0, fit_intercept=False, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1000000000000.0, fit_intercept=False, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1000000000000.0, fit_intercept=False, solver='liblinear')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "logreg = LogisticRegression(\n",
    "    solver='liblinear',\n",
    "    C=1e12,\n",
    "    fit_intercept=False\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "Generate predictions for the training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "y_hat_train = logreg.predict(X_train)\n",
    "y_hat_test = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many times was the classifier correct on the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    194\n",
      "1     33\n",
      "Name: count, dtype: int64\n",
      "------------------------------------\n",
      "target\n",
      "0    0.854626\n",
      "1    0.145374\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# We could subtract the two columns. If values or equal, difference will be zero. \n",
    "# Then count number of zeros.\n",
    "residuals = np.abs(y_train - y_hat_train)\n",
    "print(pd.Series(residuals).value_counts())\n",
    "print('------------------------------------')\n",
    "print(pd.Series(residuals).value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many times was the classifier correct on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    63\n",
      "1    13\n",
      "Name: count, dtype: int64\n",
      "------------------------------------\n",
      "target\n",
      "0    0.828947\n",
      "1    0.171053\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We could subtract the two columns. If values or equal, difference will be zero. Then count number of zeros.\n",
    "residuals = np.abs(y_test - y_hat_test)\n",
    "print(pd.Series(residuals).value_counts())\n",
    "print('------------------------------------')\n",
    "print(pd.Series(residuals).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "Describe how well you think this initial model is performing based on the training and test performance. Within your description, make note of how you evaluated performance as compared to your previous work with regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In this instance, our model predicts the majority class well, with roughly \\n85% predicted for the training set and 83% for the test set. The predicted class \\nproportions are similar between train and test, suggesting the model generalizes \\nreasonably well. However, without a confusion matrix, we cannot confirm the \\nbalance of False Positives and False Negatives.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"In this instance, our model predicts the majority class well, with roughly \n",
    "85% predicted for the training set and 83% for the test set. The predicted class \n",
    "proportions are similar between train and test, suggesting the model generalizes \n",
    "reasonably well. However, without a confusion matrix, we cannot confirm the \n",
    "balance of False Positives and False Negatives.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the confusion matrix for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24,  9],\n",
       "       [ 4, 39]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mat=confusion_matrix(y_test,y_hat_test)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot confussion matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "conf_mat=confusion_matrix(y_test,y_hat_test)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Negatives (TN): 24 → actual 0, predicted 0\n",
    "\n",
    "False Positives (FP): 9 → actual 0, predicted 1\n",
    "\n",
    "False Negatives (FN): 4 → actual 1, predicted 0\n",
    "\n",
    "True Positives (TP): 39 → actual 1, predicted 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is doing very well on class 1, with high recall (~91%), meaning it catches most of the positive cases.\n",
    "\n",
    "There are slightly more False Positives (9) than False Negatives (4), so it errs a bit more by predicting class 1 incorrectly.\n",
    "\n",
    "Accuracy is high (~83%), but given the balance of classes, it’s also important to consider precision/recall, which show that the model is reasonably balanced and not just predicting the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.73      0.79        33\n",
      "           1       0.81      0.91      0.86        43\n",
      "\n",
      "    accuracy                           0.83        76\n",
      "   macro avg       0.83      0.82      0.82        76\n",
      "weighted avg       0.83      0.83      0.83        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,y_hat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Class 0`:\n",
    "\n",
    "Precision = 0.86 → Of all the times the model predicted class 0, 86% were correct.\n",
    "\n",
    "Recall = 0.73 → Of all the actual class 0 instances, the model correctly identified 73%.\n",
    "\n",
    "F1-score = 0.79 → The harmonic mean of precision and recall, giving a balanced view.\n",
    "\n",
    "`Class 1`:\n",
    "\n",
    "Precision = 0.81 → Of all the times the model predicted class 1, 81% were correct.\n",
    "\n",
    "Recall = 0.91 → Of all the actual class 1 instances, the model correctly identified 91%.\n",
    "\n",
    "F1-score = 0.86 → A strong balance between precision and recall for class 1.\n",
    "`\n",
    "Interpretation:`\n",
    "\n",
    "The model is better at identifying class 1 (high recall 0.91) than class 0.\n",
    "\n",
    "For class 0, recall is lower (0.73), so some class 0 instances are being misclassified as class 1 (False Positives).\n",
    "\n",
    "`Accuracy` = 0.83 → Overall, 83% of predictions are correct.\n",
    "\n",
    "`Macro avg` → Simple average across classes:\n",
    "\n",
    " `Precision`: 0.83\n",
    "\n",
    " `Recall`: 0.82\n",
    "\n",
    " `F1-score`: 0.82\n",
    "This treats both classes equally, regardless of support.\n",
    "\n",
    "`Weighted avg` → Averages metrics accounting for class support (number of samples per class).\n",
    "\n",
    " Weighted precision, recall, F1 = ~0.83, reflecting that the model’s performance aligns with the class distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Overall Interpretation`\n",
    "\n",
    "`The model achieves an overall accuracy of 83%, indicating that most predictions are correct. Class-wise performance shows that it predicts class 1 very well, with high recall (91%) and F1-score (0.86), meaning it captures most of the positive instances. Class 0 has slightly lower recall (73%), so some class 0 instances are misclassified as class 1, but precision remains high (86%). Overall, the balanced F1-scores and weighted averages suggest the model performs reasonably well across both classes, though there is minor misclassification of the minority class.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you practiced a standard data science pipeline: importing data, split it into training and test sets, and fit a logistic regression model. In the upcoming labs and lessons, you'll continue to investigate how to analyze and tune these models for various scenarios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
